from pathlib import Path
import shutil
from langchain_community.document_loaders import PyPDFLoader, TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
import chromadb
from chromadb.config import Settings

# ==========================================================
# ğŸ§  ì„¸ì…˜ë³„ ì±„ìš© ê³µê³  ë¬¸ë§¥(Vector DB) ê´€ë¦¬ ëª¨ë“ˆ
# ----------------------------------------------------------
# - ê° ì„¸ì…˜(chat_id)ë§ˆë‹¤ ë³„ë„ì˜ Chroma DBë¥¼ ìƒì„± ë° ì €ì¥
# - Streamlit Cloud í™˜ê²½ í˜¸í™˜ (telemetry ë¹„í™œì„±í™”)
# - ì˜¤ë˜ëœ ì„¸ì…˜ ë””ë ‰í† ë¦¬ ìë™ ì •ë¦¬
# ==========================================================

ROOT = Path(__file__).resolve().parents[1]
SESS_DB_ROOT = ROOT / "db" / "sessions"
SESS_DB_ROOT.mkdir(parents=True, exist_ok=True)


def _load_docs(file_path: str):
    """
    ğŸ“„ íŒŒì¼ ë¡œë”
    -----------------
    íŒŒì¼ í™•ì¥ìì— ë”°ë¼ ì ì ˆí•œ ë¡œë” ì„ íƒ:
      - PDF â†’ PyPDFLoader
      - TXT â†’ TextLoader
    """
    p = Path(file_path)
    if p.suffix.lower() == ".pdf":
        return PyPDFLoader(str(p)).load()
    return TextLoader(str(p), encoding="utf-8").load()


def create_or_reset_session(chat_id: str, job_file_path: str):
    """
    ğŸ”„ ì„¸ì…˜ ìƒì„± / ë¦¬ì…‹
    ----------------------------------
    1ï¸âƒ£ ì±„ìš© ê³µê³  íŒŒì¼ì„ ë¶ˆëŸ¬ì™€ ë¬¸ì„œ ì¡°ê°ìœ¼ë¡œ ë¶„í• 
    2ï¸âƒ£ OpenAI Embedding ìƒì„±
    3ï¸âƒ£ ì„¸ì…˜ë³„ Chroma VectorStoreì— ì €ì¥ (ìë™ ì§€ì†)

    ë§¤ë²ˆ ìƒˆë¡œ ìƒì„± ì‹œ ê¸°ì¡´ ì„¸ì…˜ ë””ë ‰í† ë¦¬ë¥¼ ì •ë¦¬í•¨.
    """
    # 1. ë¬¸ì„œ ë¡œë“œ ë° ë¶„í• 
    docs = _load_docs(job_file_path)
    splitter = RecursiveCharacterTextSplitter(chunk_size=900, chunk_overlap=200)
    chunks = splitter.split_documents(docs)
    for ch in chunks:
        ch.metadata = {"chat_id": chat_id}  # ë©”íƒ€ë°ì´í„°ì— ì„¸ì…˜ ID ì¶”ê°€

    persist_dir = str(SESS_DB_ROOT / chat_id)

    # 2. ê¸°ì¡´ ì„¸ì…˜ ë°ì´í„° ì‚­ì œ (ê¹¨ì§„ DB ë°©ì§€)
    if Path(persist_dir).exists():
        shutil.rmtree(persist_dir, ignore_errors=True)

    # 3. ì„ë² ë”© ëª¨ë¸ ì§€ì •
    embeddings = OpenAIEmbeddings(model="text-embedding-3-small")

    # 4. ì•ˆì • ë²„ì „ìš© Chroma í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
    client_settings = Settings(
        anonymized_telemetry=False,  # ğŸ”• í´ë¼ìš°ë“œ í™˜ê²½ì—ì„œ ì˜¤ë¥˜ ë°©ì§€
        is_persistent=True,
        allow_reset=True,
        persist_directory=persist_dir,
    )

    # 5. ë¬¸ì„œë¡œë¶€í„° ë²¡í„° DB ìƒì„± (ìë™ ì €ì¥)
    Chroma.from_documents(
        chunks,
        embedding=embeddings,
        persist_directory=persist_dir,
        client_settings=client_settings,
    )

    return {"chat_id": chat_id, "persist_dir": persist_dir}


def retrieve_job_context(chat_id: str, query: str = "Evaluate candidate against this job"):
    """
    ğŸ” ì±„ìš© ê³µê³  ë¬¸ë§¥ ê²€ìƒ‰
    ----------------------------------
    - ì„¸ì…˜ë³„ Chroma DBì—ì„œ ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰
    - ìƒìœ„ kê°œ ì¡°ê°ì„ í•©ì³ ë°˜í™˜
    """
    persist_dir = str(SESS_DB_ROOT / chat_id)
    embeddings = OpenAIEmbeddings(model="text-embedding-3-small")

    # ì„¸ì…˜ë³„ DB ë¡œë“œ
    db = Chroma(persist_directory=persist_dir, embedding_function=embeddings)
    hits = db.similarity_search(query, k=4)
    return "\n\n".join([h.page_content for h in hits])


def end_session(chat_id: str):
    """
    ğŸ§¹ ì„¸ì…˜ ì¢…ë£Œ ë° ì •ë¦¬
    ----------------------------------
    - ì„¸ì…˜ ê´€ë ¨ ë””ìŠ¤í¬ ë°ì´í„°ë¥¼ ì‚­ì œí•˜ì—¬ ê³µê°„ í™•ë³´
    - Streamlit Cloud í™˜ê²½ì—ì„œë„ ì•ˆì „í•˜ê²Œ ë™ì‘
    """
    dirp = SESS_DB_ROOT / chat_id
    if dirp.exists():
        shutil.rmtree(dirp, ignore_errors=True)
